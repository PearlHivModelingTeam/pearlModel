{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare imports\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# import dask.dataframe as dd\n",
    "# from pandas.api.types import is_numeric_dtype\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib as mpl\n",
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# import seaborn as sns\n",
    "# import colorcet as cc\n",
    "# import math\n",
    "# from pearllib import group_title_dict, NA_ACCORD_group_title_dict\n",
    "# import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import dask.dataframe as dd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "import colorcet as cc\n",
    "\n",
    "path_to_functions = os.path.abspath(\"../src\")\n",
    "\n",
    "# Add this folder to the system path\n",
    "sys.path.append(path_to_functions)\n",
    "\n",
    "from pearl.post_processing.bmi import (\n",
    "    add_summary,\n",
    "    calc_overall_risk,\n",
    "    calc_percentage,\n",
    "    calc_percentage_and_add_summary,\n",
    "    calc_risk_by_group,\n",
    "    clean_control,\n",
    "    create_summary_table,\n",
    "    group_order,\n",
    "    group_order_with_sub_total,\n",
    "    group_title_dict,\n",
    "    palette,\n",
    "    rearrange_group_order,\n",
    "    round_thousand,\n",
    "    calc_dm_prop,\n",
    "    add_sub_total,\n",
    "    calc_overall_bmi_risk,\n",
    ")\n",
    "\n",
    "start_time = datetime.now()\n",
    "df_summary_dict = {}\n",
    "\n",
    "# Define the argument parser\n",
    "\n",
    "baseline_dir = Path('../out/S0_10/combined')\n",
    "variable_dir = Path('../out/S3_10/combined')\n",
    "out_dir = Path('../results')\n",
    "\n",
    "start_year = 2013\n",
    "end_year = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Group Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_order = [\n",
    "    \"Black HET Women\",\n",
    "    \"White HET Women\",\n",
    "    \"Hispanic HET Women\",\n",
    "    \"Black HET Men\",\n",
    "    \"White HET Men\",\n",
    "    \"Hispanic HET Men\",\n",
    "    \"Black WWID\",\n",
    "    \"White WWID\",\n",
    "    \"Hispanic WWID\",\n",
    "    \"Black MWID\",\n",
    "    \"White MWID\",\n",
    "    \"Hispanic MWID\",\n",
    "    \"Black MSM\",\n",
    "    \"White MSM\",\n",
    "    \"Hispanic MSM\",\n",
    "    \"Overall\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Color Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define color pallete\n",
    "palette = sns.color_palette(cc.glasbey_light, n_colors=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_thousand = lambda x: int(math.ceil(x / 100.0)) * 100 if  x > 1000 else x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Risk Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_risk_by_group_old(df, years_follow_up):\n",
    "\n",
    "    # filter for only x-year follow up with dm\n",
    "    df_follow_up = df.loc[(df['years_after_h1yy'] > 0) & (df['years_after_h1yy'] <= years_follow_up)]\n",
    "\n",
    "    # group by replication and group and sum\n",
    "    df_follow_up_sum = df_follow_up.groupby(['group', 'replication'])['n'].sum().reset_index()\n",
    "    df_follow_up_sum = df_follow_up_sum.rename(columns={'n': 'dm_num'})\n",
    "\n",
    "    # group by replication and group and sum\n",
    "    df_all_sum = df.groupby(['group', 'replication'])['n'].sum().reset_index()\n",
    "    df_all_sum = df_all_sum.rename(columns={'n': 'num'})\n",
    "\n",
    "    # merge dataframes\n",
    "    group_dm_risk_table = dd.merge(df_follow_up_sum, df_all_sum, how='left')\n",
    "\n",
    "    # calculate risk\n",
    "    group_dm_risk_table['risk'] = group_dm_risk_table['dm_num'] / group_dm_risk_table['num']\n",
    "\n",
    "    return group_dm_risk_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Data Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_type = 'baseline'\n",
    "\n",
    "if config_type != 'baseline':\n",
    "    config_file_path = f'../config/S0_{config_type}.yaml' #gitignore\n",
    "\n",
    "    # Load the YAML file\n",
    "    with open(config_file_path, 'r') as file:\n",
    "        config_data = yaml.safe_load(file)\n",
    "    \n",
    "    coverage_rate = config_data['bmi_intervention_coverage']\n",
    "    effectiveness = config_data['bmi_intervention_effectiveness']\n",
    "    \n",
    "    # Set path to input folder\n",
    "    s0_data_dir = Path(f\"../out/S0_{config_type}/combined/\") #gitignore\n",
    "    s1_data_dir = Path(f\"../out/S3_{config_type}/combined/\") #gitignore\n",
    "else:\n",
    "    # For Baseline running\n",
    "    s0_data_dir = Path(f\"../out/S0_10/combined/\") #gitignore\n",
    "    s1_data_dir = Path(f\"../out/S3_10/combined/\") #gitignore\n",
    "\n",
    "    coverage_rate = 1\n",
    "    effectiveness = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_summary_df = pd.DataFrame()\n",
    "SA_summary_df['group'] = [\n",
    "        \"Black HET Women\",\n",
    "        \"White HET Women\",\n",
    "        \"Hispanic HET Women\",\n",
    "        \"Black HET Men\",\n",
    "        \"White HET Men\",\n",
    "        \"Hispanic HET Men\",\n",
    "        \"Black WWID\",\n",
    "        \"White WWID\",\n",
    "        \"Hispanic WWID\",\n",
    "        \"Black MWID\",\n",
    "        \"White MWID\",\n",
    "        \"Hispanic MWID\",\n",
    "        \"Black MSM\",\n",
    "        \"White MSM\",\n",
    "        \"Hispanic MSM\",\n",
    "        \"Overall\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of People received BMI intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>years_after_h1yy</th>\n",
       "      <th>replication</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>1</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>2</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>3</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>4</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4319 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 group  years_after_h1yy  replication    n\n",
       "0     het_black_female             -2017            0  905\n",
       "1     het_black_female             -2017            1  890\n",
       "2     het_black_female             -2017            2  915\n",
       "3     het_black_female             -2017            3  981\n",
       "4     het_black_female             -2017            4  858\n",
       "...                ...               ...          ...  ...\n",
       "4314           overall                22            5  457\n",
       "4315           overall                22            6  475\n",
       "4316           overall                22            7  455\n",
       "4317           overall                22            8  437\n",
       "4318           overall                22            9  456\n",
       "\n",
       "[4319 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will look at the \"bmi_int_dm_prev.h5\" for S0\n",
    "bmi_int_dm_prev = dd.read_parquet(s0_data_dir /'dm_final_output.parquet').reset_index()\n",
    "\n",
    "# Add Overall\n",
    "all_but_group = list(bmi_int_dm_prev.columns[1:])\n",
    "bmi_int_dm_prev_overall = bmi_int_dm_prev.groupby(all_but_group).sum().reset_index()\n",
    "bmi_int_dm_prev_overall['group'] = 'overall'\n",
    "bmi_int_dm_prev = dd.concat([bmi_int_dm_prev, bmi_int_dm_prev_overall], ignore_index=True)\n",
    "\n",
    "# type the dataframe for space efficiency\n",
    "bmi_int_dm_prev = bmi_int_dm_prev.astype({'group':'str', 'replication':'int16', 'bmiInt_scenario':np.int8, 'h1yy': np.int16, 'bmiInt_impacted':bool, 'dm': bool, 't_dm': np.int16, 'n': np.int16})\n",
    "\n",
    "# clean to control specifications\n",
    "control_bmi_int_dm_prev = clean_control(bmi_int_dm_prev, only_eligible=True, only_received=True)\n",
    "\n",
    "# sum across replications, group, and years_after_h1yy\n",
    "control_bmi_int_dm_prev_agg = control_bmi_int_dm_prev.groupby(['group', 'years_after_h1yy','replication'])['n'].sum().reset_index().compute()\n",
    "\n",
    "# display table\n",
    "control_bmi_int_dm_prev_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = control_bmi_int_dm_prev_agg.groupby(['group', 'replication'])[['n']].sum().reset_index()\n",
    "df['group'] = df['group'].map(group_title_dict)\n",
    "df = df.groupby('group')[['n']].apply(lambda x: x.quantile([0.025,0.5,0.975])).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.0f} [{:.0f} - {:.0f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['Control|Number receiving intervention'] = df['formatted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>years_after_h1yy</th>\n",
       "      <th>replication</th>\n",
       "      <th>time_exposure_to_risk</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>-2017</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66008</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>-2013</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66009</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66010</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>-2013</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66011</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66012</th>\n",
       "      <td>overall</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66013 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  group  years_after_h1yy  replication  time_exposure_to_risk  \\\n",
       "0      het_black_female             -2017            0                  -2017   \n",
       "1      het_black_female             -2017            0                      0   \n",
       "2      het_black_female             -2017            0                      1   \n",
       "3      het_black_female             -2017            0                      2   \n",
       "4      het_black_female             -2017            0                      3   \n",
       "...                 ...               ...          ...                    ...   \n",
       "66008           overall                22            8                  -2013   \n",
       "66009           overall                22            8                     22   \n",
       "66010           overall                22            9                  -2013   \n",
       "66011           overall                22            9                     22   \n",
       "66012           overall                 5            1                     22   \n",
       "\n",
       "          n  \n",
       "0      1211  \n",
       "1        21  \n",
       "2        24  \n",
       "3        18  \n",
       "4        21  \n",
       "...     ...  \n",
       "66008   549  \n",
       "66009    16  \n",
       "66010   563  \n",
       "66011    18  \n",
       "66012     3  \n",
       "\n",
       "[66013 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will work on the remaining percentage columns\n",
    "bmi_int_cascade = dd.read_parquet(s0_data_dir / 'bmi_int_cascade.parquet').reset_index()\n",
    "# filter for only starting h1yy after 2013 and before 2017\n",
    "s0_bmi_int_cascade = bmi_int_cascade.loc[(bmi_int_cascade['h1yy'] >= start_year) & (bmi_int_cascade['h1yy'] <= 2017)]\n",
    "\n",
    "\n",
    "# we will look at the \"bmi_int_dm_prev.h5\" for S0\n",
    "bmi_int_dm_prev = dd.read_parquet(s0_data_dir /'dm_final_output.parquet').reset_index()\n",
    "\n",
    "# Add Overall\n",
    "all_but_group = list(bmi_int_dm_prev.columns[1:])\n",
    "bmi_int_dm_prev_overall = bmi_int_dm_prev.groupby(all_but_group).sum().reset_index()\n",
    "bmi_int_dm_prev_overall['group'] = 'overall'\n",
    "bmi_int_dm_prev = dd.concat([bmi_int_dm_prev, bmi_int_dm_prev_overall], ignore_index=True)\n",
    "\n",
    "# type the dataframe for space efficiency\n",
    "bmi_int_dm_prev = bmi_int_dm_prev.astype({'group':'str', 'replication':'int16', 'bmiInt_scenario':np.int8, 'h1yy': np.int16, 'bmiInt_impacted':bool, 'dm': bool, 't_dm': np.int16, 'n': np.int16})\n",
    "\n",
    "# clean to control specifications\n",
    "control_bmi_int_dm_prev = clean_control(bmi_int_dm_prev, only_eligible=False)\n",
    "\n",
    "# sum across replications, group, and years_after_h1yy\n",
    "control_bmi_int_dm_prev_agg = control_bmi_int_dm_prev.groupby(['group', 'years_after_h1yy','replication',\"time_exposure_to_risk\"])['n'].sum().reset_index().compute()\n",
    "\n",
    "# display table\n",
    "control_bmi_int_dm_prev_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of new dm & risk events during 7 year follow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dm_risk_table = calc_risk_by_group(control_bmi_int_dm_prev_agg, 7).compute()\n",
    "\n",
    "group_dm_risk_table['group'] = group_dm_risk_table['group'].map(group_title_dict)\n",
    "\n",
    "# New DM\n",
    "df = group_dm_risk_table.groupby('group')[['dm_num']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.1f} [{:.1f} - {:.1f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['Control|Number of new dm events during 7 year follow up'] = df['formatted']\n",
    "\n",
    "# DM Risk\n",
    "df = group_dm_risk_table.groupby('group')[['risk']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.3f} [{:.3f} - {:.3f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['Control|7 year risk of dm'] = df['formatted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of dm per 1000 receiving the intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will look at the \"bmi_int_dm_prev.h5\" for S0\n",
    "bmi_int_dm_prev = dd.read_parquet(s0_data_dir /'dm_final_output.parquet').reset_index()\n",
    "\n",
    "# Add Overall\n",
    "all_but_group = list(bmi_int_dm_prev.columns[1:])\n",
    "bmi_int_dm_prev_overall = bmi_int_dm_prev.groupby(all_but_group).sum().reset_index()\n",
    "bmi_int_dm_prev_overall['group'] = 'overall'\n",
    "bmi_int_dm_prev = dd.concat([bmi_int_dm_prev, bmi_int_dm_prev_overall], ignore_index=True)\n",
    "\n",
    "# type the dataframe for space efficiency\n",
    "bmi_int_dm_prev = bmi_int_dm_prev.astype({'group':'str', 'replication':'int16', 'bmiInt_scenario':np.int8, 'h1yy': np.int16, 'bmiInt_impacted':bool, 'dm': bool, 't_dm': np.int16, 'n': np.int16})\n",
    "\n",
    "# clean to control specifications\n",
    "control_bmi_int_dm_prev = clean_control(bmi_int_dm_prev, only_eligible=True, only_received=True)\n",
    "\n",
    "# sum across replications, group, and years_after_h1yy\n",
    "control_bmi_int_dm_prev_agg = control_bmi_int_dm_prev.groupby(['group', 'years_after_h1yy','replication', \"time_exposure_to_risk\"])['n'].sum().reset_index().compute()\n",
    "\n",
    "group_dm_risk_table = calc_risk_by_group_old(control_bmi_int_dm_prev_agg, 7).compute()\n",
    "\n",
    "group_dm_risk_table['group'] = group_dm_risk_table['group'].map(group_title_dict)\n",
    "\n",
    "group_dm_risk_table['dm_per_1000'] = np.round(group_dm_risk_table['risk']*1000,0)\n",
    "\n",
    "# New DM\n",
    "df = group_dm_risk_table.groupby('group')[['dm_per_1000']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.1f} [{:.1f} - {:.1f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['Control|nubmer of dm event per 1000 people receiving intervention'] = df['formatted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervention Arm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of people received intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will look at the \"bmi_int_dm_prev.h5\" for S1\n",
    "bmi_int_dm_prev = dd.read_parquet(s1_data_dir /'dm_final_output.parquet').reset_index()\n",
    "\n",
    "# Add Overall\n",
    "all_but_group = list(bmi_int_dm_prev.columns[1:])\n",
    "bmi_int_dm_prev_overall = bmi_int_dm_prev.groupby(all_but_group).sum().reset_index()\n",
    "bmi_int_dm_prev_overall['group'] = 'overall'\n",
    "bmi_int_dm_prev = dd.concat([bmi_int_dm_prev, bmi_int_dm_prev_overall], ignore_index=True)\n",
    "\n",
    "# type the dataframe for space efficiency\n",
    "bmi_int_dm_prev = bmi_int_dm_prev.astype({'group':'str', 'replication':'int16', 'bmiInt_scenario':np.int8, 'h1yy': np.int16, 'bmiInt_impacted':bool, 'dm': bool, 't_dm': np.int16, 'n': np.int16})\n",
    "\n",
    "# clean to control specifications\n",
    "control_bmi_int_dm_prev = clean_control(bmi_int_dm_prev, only_eligible=True, only_received=True)\n",
    "\n",
    "# sum across replications, group, and years_after_h1yy\n",
    "control_bmi_int_dm_prev_agg = control_bmi_int_dm_prev.groupby(['group', 'years_after_h1yy','replication', \"time_exposure_to_risk\"])['n'].sum().reset_index().compute()\n",
    "\n",
    "# display table\n",
    "control_bmi_int_dm_prev_agg\n",
    "\n",
    "df = control_bmi_int_dm_prev_agg.groupby(['group', 'replication'])[['n']].sum().reset_index()\n",
    "df['group'] = df['group'].map(group_title_dict)\n",
    "df = df.groupby('group')[['n']].apply(lambda x: x.quantile([0.025,0.5,0.975])).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.0f} [{:.0f} - {:.0f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['Intervention|Number receiving intervention'] = df['formatted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will look at the \"bmi_int_dm_prev.h5\" for S1\n",
    "bmi_int_dm_prev = dd.read_parquet(s1_data_dir /'dm_final_output.parquet').reset_index()\n",
    "\n",
    "# Add Overall\n",
    "all_but_group = list(bmi_int_dm_prev.columns[1:])\n",
    "bmi_int_dm_prev_overall = bmi_int_dm_prev.groupby(all_but_group).sum().reset_index()\n",
    "bmi_int_dm_prev_overall['group'] = 'overall'\n",
    "bmi_int_dm_prev = dd.concat([bmi_int_dm_prev, bmi_int_dm_prev_overall], ignore_index=True)\n",
    "\n",
    "# type the dataframe for space efficiency\n",
    "bmi_int_dm_prev = bmi_int_dm_prev.astype({'group':'str', 'replication':'int16', 'bmiInt_scenario':np.int8, 'h1yy': np.int16, 'bmiInt_impacted':bool, 'dm': bool, 't_dm': np.int16, 'n': np.int16})\n",
    "\n",
    "# clean to control specifications\n",
    "control_bmi_int_dm_prev = clean_control(bmi_int_dm_prev, only_eligible=True, only_received=True)\n",
    "\n",
    "# sum across replications, group, and years_after_h1yy\n",
    "control_bmi_int_dm_prev_agg = control_bmi_int_dm_prev.groupby(['group', 'years_after_h1yy','replication', \"time_exposure_to_risk\"])['n'].sum().reset_index().compute()\n",
    "\n",
    "# display table\n",
    "control_bmi_int_dm_prev_agg\n",
    "\n",
    "df = control_bmi_int_dm_prev_agg.groupby(['group', 'replication'])[['n']].sum().reset_index()\n",
    "df['group'] = df['group'].map(group_title_dict)\n",
    "df = df.groupby('group')[['n']].apply(lambda x: x.quantile([0.025,0.5,0.975])).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.0f} [{:.0f} - {:.0f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['Intervention|Number receiving intervention'] = df['formatted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>years_after_h1yy</th>\n",
       "      <th>replication</th>\n",
       "      <th>time_exposure_to_risk</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>-2017</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>het_black_female</td>\n",
       "      <td>-2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64942</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>-2013</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64943</th>\n",
       "      <td>overall</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64944</th>\n",
       "      <td>overall</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64945</th>\n",
       "      <td>overall</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64946</th>\n",
       "      <td>overall</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64947 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  group  years_after_h1yy  replication  time_exposure_to_risk  \\\n",
       "0      het_black_female             -2017            0                  -2017   \n",
       "1      het_black_female             -2017            0                      0   \n",
       "2      het_black_female             -2017            0                      1   \n",
       "3      het_black_female             -2017            0                      2   \n",
       "4      het_black_female             -2017            0                      3   \n",
       "...                 ...               ...          ...                    ...   \n",
       "64942           overall                22            9                  -2013   \n",
       "64943           overall                22            9                     22   \n",
       "64944           overall                 1            6                     22   \n",
       "64945           overall                 2            3                     21   \n",
       "64946           overall                 3            3                     22   \n",
       "\n",
       "          n  \n",
       "0      1305  \n",
       "1        17  \n",
       "2        18  \n",
       "3        20  \n",
       "4        21  \n",
       "...     ...  \n",
       "64942   523  \n",
       "64943     7  \n",
       "64944     4  \n",
       "64945     9  \n",
       "64946     2  \n",
       "\n",
       "[64947 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will work on the remaining percentage columns\n",
    "bmi_int_cascade = dd.read_parquet(s1_data_dir / 'bmi_int_cascade.parquet').reset_index()\n",
    "# filter for only starting h1yy after 2013 and before 2017\n",
    "s1_bmi_int_cascade = bmi_int_cascade.loc[(bmi_int_cascade['h1yy'] >= start_year) & (bmi_int_cascade['h1yy'] <= 2017)]\n",
    "\n",
    "# we will look at the \"bmi_int_dm_prev.h5\" for S1\n",
    "bmi_int_dm_prev = dd.read_parquet(s1_data_dir /'dm_final_output.parquet').reset_index()\n",
    "\n",
    "# Add Overall\n",
    "all_but_group = list(bmi_int_dm_prev.columns[1:])\n",
    "bmi_int_dm_prev_overall = bmi_int_dm_prev.groupby(all_but_group).sum().reset_index()\n",
    "bmi_int_dm_prev_overall['group'] = 'overall'\n",
    "bmi_int_dm_prev = dd.concat([bmi_int_dm_prev, bmi_int_dm_prev_overall], ignore_index=True)\n",
    "\n",
    "# type the dataframe for space efficiency\n",
    "bmi_int_dm_prev = bmi_int_dm_prev.astype({'group':'str', 'replication':'int16', 'bmiInt_scenario':np.int8, 'h1yy': np.int16, 'bmiInt_impacted':bool, 'dm': bool, 't_dm': np.int16, 'n': np.int16})\n",
    "\n",
    "# clean to control specifications\n",
    "s1_bmi_int_dm_prev = clean_control(bmi_int_dm_prev, only_eligible=False)\n",
    "\n",
    "# sum across replications, group, and years_after_h1yy\n",
    "s1_bmi_int_dm_prev_agg = s1_bmi_int_dm_prev.groupby(['group', 'years_after_h1yy','replication', \"time_exposure_to_risk\"])['n'].sum().reset_index().compute()\n",
    "\n",
    "# display table\n",
    "s1_bmi_int_dm_prev_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of new dm & risk events during 7 year follow up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dm_risk_table = calc_risk_by_group(s1_bmi_int_dm_prev_agg, 7).compute()\n",
    "\n",
    "group_dm_risk_table['group'] = group_dm_risk_table['group'].map(group_title_dict)\n",
    "\n",
    "# New DM\n",
    "df = group_dm_risk_table.groupby('group')[['dm_num']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.1f} [{:.1f} - {:.1f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['Intervention|Number of new dm events during 7 year follow up'] = df['formatted']\n",
    "\n",
    "# DM Risk\n",
    "df = group_dm_risk_table.groupby('group')[['risk']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.3f} [{:.3f} - {:.3f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['Intervention|7 year risk of dm'] = df['formatted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of dm per 1000 receiving the intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will look at the \"bmi_int_dm_prev.h5\" for S1\n",
    "bmi_int_dm_prev = dd.read_parquet(s1_data_dir /'dm_final_output.parquet').reset_index()\n",
    "\n",
    "# Add Overall\n",
    "all_but_group = list(bmi_int_dm_prev.columns[1:])\n",
    "bmi_int_dm_prev_overall = bmi_int_dm_prev.groupby(all_but_group).sum().reset_index()\n",
    "bmi_int_dm_prev_overall['group'] = 'overall'\n",
    "bmi_int_dm_prev = dd.concat([bmi_int_dm_prev, bmi_int_dm_prev_overall], ignore_index=True)\n",
    "\n",
    "# type the dataframe for space efficiency\n",
    "bmi_int_dm_prev = bmi_int_dm_prev.astype({'group':'str', 'replication':'int16', 'bmiInt_scenario':np.int8, 'h1yy': np.int16, 'bmiInt_impacted':bool, 'dm': bool, 't_dm': np.int16, 'n': np.int16})\n",
    "\n",
    "# clean to control specifications\n",
    "s1_bmi_int_dm_prev = clean_control(bmi_int_dm_prev, only_eligible=True, only_received=True)\n",
    "\n",
    "# sum across replications, group, and years_after_h1yy\n",
    "s1_bmi_int_dm_prev_agg = s1_bmi_int_dm_prev.groupby(['group', 'years_after_h1yy','replication', \"time_exposure_to_risk\"])['n'].sum().reset_index().compute()\n",
    "\n",
    "group_dm_risk_table = calc_risk_by_group_old(s1_bmi_int_dm_prev_agg, 7).compute()\n",
    "\n",
    "group_dm_risk_table['group'] = group_dm_risk_table['group'].map(group_title_dict)\n",
    "\n",
    "group_dm_risk_table['dm_per_1000'] = np.round(group_dm_risk_table['risk']*1000,0)\n",
    "\n",
    "# New DM\n",
    "df = group_dm_risk_table.groupby('group')[['dm_per_1000']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.1f} [{:.1f} - {:.1f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['Intervention|nubmer of dm event per 1000 people receiving intervention'] = df['formatted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will look at the \"bmi_int_dm_prev.h5\" for S1\n",
    "bmi_int_dm_prev_s1 = dd.read_parquet(s1_data_dir /'dm_final_output.parquet').reset_index()\n",
    "bmi_int_dm_prev_s1 = bmi_int_dm_prev_s1.astype({'group':'str', 'replication':'int16', 'bmiInt_scenario':np.int8, 'h1yy': np.int16, 'bmiInt_impacted':bool, 'dm': bool, 't_dm': np.int16, 'n': np.int16})\n",
    "\n",
    "# Add Overall\n",
    "all_but_group = list(bmi_int_dm_prev_s1.columns[1:])\n",
    "bmi_int_dm_prev_s1_overall = bmi_int_dm_prev_s1.groupby(all_but_group).sum().reset_index()\n",
    "bmi_int_dm_prev_s1_overall['group'] = 'overall'\n",
    "bmi_int_dm_prev_s1 = dd.concat([bmi_int_dm_prev_s1, bmi_int_dm_prev_s1_overall], ignore_index=True)\n",
    "\n",
    "# clean to control specifications\n",
    "control_bmi_int_dm_prev_s1 = clean_control(bmi_int_dm_prev_s1, only_eligible=True, only_received = True)\n",
    "\n",
    "# filter for only people eligible for intervention\n",
    "bmi_int_s1_eligible_risk = calc_risk_by_group(control_bmi_int_dm_prev_s1, 7)\n",
    "\n",
    "bmi_int_s1_eligible_risk['received_num'] = bmi_int_s1_eligible_risk['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will look at the \"bmi_int_dm_prev.h5\" for S0\n",
    "bmi_int_dm_prev = dd.read_parquet(s0_data_dir /'dm_final_output.parquet').reset_index()\n",
    "\n",
    "# Add Overall\n",
    "all_but_group = list(bmi_int_dm_prev.columns[1:])\n",
    "bmi_int_dm_prev_overall = bmi_int_dm_prev.groupby(all_but_group).sum().reset_index()\n",
    "bmi_int_dm_prev_overall['group'] = 'overall'\n",
    "bmi_int_dm_prev = dd.concat([bmi_int_dm_prev, bmi_int_dm_prev_overall], ignore_index=True)\n",
    "\n",
    "# type the dataframe for space efficiency\n",
    "bmi_int_dm_prev = bmi_int_dm_prev.astype({'group':'str', 'replication':'int16', 'bmiInt_scenario':np.int8, 'h1yy': np.int16, 'bmiInt_impacted':bool, 'dm': bool, 't_dm': np.int16, 'n': np.int16})\n",
    "\n",
    "# clean to control specifications\n",
    "control_bmi_int_dm_prev = clean_control(bmi_int_dm_prev, only_eligible=True,only_received = True)\n",
    "\n",
    "bmi_int_eligible_risk = calc_risk_by_group(control_bmi_int_dm_prev, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackz\\AppData\\Local\\Temp\\ipykernel_43232\\1978859321.py:3: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  s0_sample = bmi_int_eligible_risk.groupby('group').apply(lambda x: x.sample(num_samples, replace=True)).reset_index(drop=True).compute()\n"
     ]
    }
   ],
   "source": [
    "num_samples = 2000\n",
    "\n",
    "s0_sample = bmi_int_eligible_risk.groupby('group').apply(lambda x: x.sample(num_samples, replace=True)).reset_index(drop=True).compute()\n",
    "s1_sample = bmi_int_s1_eligible_risk.groupby('group').apply(lambda x: x.sample(num_samples, replace=True)).reset_index(drop=True).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0_sample = s0_sample.sort_values(by = 'group').reset_index(drop = True)\n",
    "s0_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_sample = s1_sample.sort_values(by = 'group').reset_index(drop = True)\n",
    "s1_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## abs change in risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute difference\n",
    "abs_sample_diff = s1_sample[['dm_num', 'risk']] - s0_sample[['dm_num', 'risk']]\n",
    "abs_sample_diff['group'] = s0_sample['group']\n",
    "abs_sample_diff['received_num'] = s1_sample['received_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_sample_diff_plot = abs_sample_diff.copy()\n",
    "abs_sample_diff_plot['group'] = abs_sample_diff_plot['group'].map(group_title_dict)\n",
    "\n",
    "# diff_ax = sns.boxplot(x=abs_sample_diff_plot['group'],\n",
    "#             y=abs_sample_diff_plot['risk'],\n",
    "#             color='seagreen',\n",
    "#             showfliers = False,\n",
    "#             palette=palette,\n",
    "#             hue=abs_sample_diff_plot['group'],\n",
    "#             order=group_order,\n",
    "#             hue_order=group_order)\n",
    "\n",
    "# diff_ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "# diff_ax.set_xlabel('')\n",
    "# diff_ax.set_ylabel('Absolute risk reduction (ARR) of new DM diagnosis (intervention vs. control arm over 5-year follow up)')\n",
    "# diff_ax.axhline(y=0, color='r', linestyle='-')\n",
    "# diff_fig = diff_ax.get_figure()\n",
    "# diff_fig.savefig(\"../outputs/fig3a.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs_sample_diff_plot.groupby('group')[['risk']].median().to_csv('../outputs/figure3a_table.csv')\n",
    "\n",
    "df = abs_sample_diff_plot.groupby('group')[['risk']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.3f} [{:.3f} - {:.3f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['absolute change in risk'] = df['formatted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relative change in risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute difference\n",
    "rel_sample_diff = (s1_sample[['risk']] - s0_sample[['risk']]) / s0_sample[['risk']]\n",
    "rel_sample_diff['group'] = s0_sample['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_sample_diff_plot = rel_sample_diff.copy()\n",
    "rel_sample_diff_plot['group'] = rel_sample_diff_plot['group'].map(group_title_dict)\n",
    "\n",
    "df = rel_sample_diff_plot.groupby('group')[['risk']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:.3f} [{:.3f} - {:.3f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['relative change in risk'] = df['formatted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number dm cases averted per 1000 & NNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_sample_diff_plot['dm_per_1000'] = -np.round(abs_sample_diff_plot['dm_num']/abs_sample_diff_plot['received_num']*1000, 0)\n",
    "abs_sample_diff_plot['NNT'] = -np.round(abs_sample_diff_plot['received_num']/abs_sample_diff_plot['dm_num'], 0)\n",
    "\n",
    "# dm cases averted per 1000\n",
    "df = abs_sample_diff_plot.groupby('group')[['dm_per_1000']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:,.0f} [{:,.0f} - {:,.0f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "SA_summary_df['num dm cases averted per 1000'] = df['formatted']\n",
    "\n",
    "# NNT\n",
    "df = abs_sample_diff_plot.groupby('group')[['NNT']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:,.0f} [{:,.0f} - {:,.0f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "SA_summary_df['NNT'] = df['formatted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total number of dm averted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_sample_diff_plot['dm_num_prevented'] = abs_sample_diff_plot['dm_num'] * -1\n",
    "\n",
    "df = abs_sample_diff_plot.groupby('group')[['dm_num_prevented']].quantile([0.025,0.5,0.975]).unstack().reset_index()\n",
    "df.columns = ['group',0.025, 0.5, 0.975]\n",
    "df['formatted'] = df.apply(\n",
    "    lambda row: '{:,.0f} [{:,.0f} - {:,.0f}]'.format(row[0.50], row[0.025], row[0.975]), axis=1\n",
    ")\n",
    "df = rearrange_group_order(df)\n",
    "\n",
    "SA_summary_df['total number of dm averted'] = df['formatted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save summary df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_summary_df.to_csv(f'../results/SA/{config_type}_cov_{coverage_rate}_eff_{effectiveness}.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
